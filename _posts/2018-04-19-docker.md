---
layout: post
title: Docker for the busy researcher
---

## Why Docker?
Have you ever been frustrated because a software package's installation instructions were incomplete?
Or have you wanted to try out software without going through a complex installation process?
Or have you wanted to execute your software on some remote machine in a defined environment?

Docker can help.

In my group, we use Docker to make sure that our code compiles properly in a defined environment and analyses are reproducible.
Our use of Docker is almost exclusively through automated creation using [Dockerfiles](https://docs.docker.com/articles/dockerfile_best-practices/).
This provides a clear list of dependencies which are guaranteed to work starting from a defined starting point.

Once a Docker image is built, it can be run anywhere that runs the Docker engine.


## Introduction to Docker
Have you ever seen someone boot up Windows on a Mac?
That process of running one complete OS on top of another OS called running a _virtual machine_.
A Docker container is like a virtual machine that shares guest OSs.

![](http://patg.net/assets/container_vs_vm.jpg)

This makes them very lightweight.
However, it's still useful to think of Docker containers as virtual machines, because Docker containers feel like their own self-contained units.
Docker images are analogous to virtual machine images, and a container is analogous to a running virtual machine.

There is a whole ecosystem around Docker containers, somewhat analogous to git repositories.

![](http://blog.octo.com/wp-content/uploads/2014/01/docker-stages.png)

[Docker Hub](https://hub.docker.com/) plays the role of GitHub (shown as a "Docker registry" above).


## Dockerfiles 1

Dockerfiles are complete instructions about how to build a Docker image.
This makes them very valuable even for people who don't want to use your software via Docker: they can read this document, knowing that it provides a complete set of installation instructions (especially if you are using an automate build as described below).


We will illustrate using an example [cowsay-test repository](https://github.com/matsen/cowsay-test).
The first line,

```docker
FROM ubuntu:trusty
```

states that the image should be built starting with the [Trusty](https://en.wikipedia.org/wiki/Ubuntu_version_history#Ubuntu_14.04_LTS_(Trusty_Tahr)) version of the Ubuntu Linux distribution.
This next section installs `cowsay` using `apt-get` (more on apt below):

```docker
RUN apt-get update -q && \
    apt-get install -y -q --no-install-recommends \
        cowsay
```

Then we link `cowsay` to someplace we can execute it.

```docker
RUN ln -s /usr/games/cowsay /usr/bin
```

## Building and running our Docker image

To build this Docker image, use the command

```
docker build -t matsen/cowsay-test .
```

inside a directory with the Dockerfile present (if you want to follow along I suggest cloning the [cowsay-test repository](https://github.com/matsen/cowsay-test)).
This builds the Docker image.

Now we can try out our Docker image.
First, note that I don't have cowsay available on the machine running Docker:

```
exmar ~/cowsay-test » cowsay
zsh: command not found: cowsay
```

But when I start and enter the Docker container, we get:

```
exmar ~/cowsay-test » docker run -it matsen/cowsay-test /bin/bash
root@5d2942f9d5e2:/test-cowsay# cowsay "Hello"
 _______
< Hello >
 -------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||
root@5d2942f9d5e2:/test-cowsay#
```

Explore around a little inside the container and note that you can't see anything from your host machine.
Also, any modifications you make inside the container don't change things on the host machine.
For the ultimate test of this, it's fun to recursively remove starting at `/`, though of course be very careful that you are actually inside the container!
In any case, when you are done you can `exit` out of the Docker image.


## Making a directory available inside of a container

As described above, Docker is designed such that changes inside the container are not reflected on the host machine.
That's perfect for some use cases, but of course if you want to keep something, you typically want it stored outside of the container.
For this Docker provides [volumes](https://docs.docker.com/storage/volumes/).

In the simplest use-case one can just use it to have a directory available in a Docker container.
The syntax is
```
-v /host/path:/container/path
```
where `/host/path` should be replaced by the directory on the host machine you wish to make available, and `/container/path` is where you would like this directory to appear inside of the container.

For example, say we have a `~/foo` directory that we would like available inside our container.
We can mount it like so:

```
docker run -v /home/matsen/foo:/foo -it matsen/cowsay-test /bin/bash
```

Once we've mounted it we can do stuff that lives beyond our container:
```
root@2cdca42bc8d9:/test-cowsay# cd /foo
root@2cdca42bc8d9:/foo# cowsay "Hello foo" > output.txt
root@2cdca42bc8d9:/foo# exit
exit
exmar ~/cowsay-test » cat ~/foo/output.txt
 ___________
< Hello foo >
 -----------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||
exmar ~/cowsay-test »
```


## A minimal list of commands

* `docker build .`: build a Docker image from this directory (assuming it contains a Dockerfile)
* `docker run <image>`: run an image, executing the `CMD` line then exiting
* `docker run -it <image> /bin/bash`: run an image and "log into" it
* `docker exec -it <container> /bin/bash`: "log into" a running container
* `docker ps -a`: shows all of the containers and their statuses


## Resources

* [Docker basics](https://docs.docker.com/get-started/)
* [Docker installation](https://docs.docker.com/install/)
* [Dockerfile best practices](https://docs.docker.com/articles/dockerfile_best-practices/)


## Our use

We use Docker to ensure that we keep track of dependencies and for [continuous testing](https://en.wikipedia.org/wiki/Continuous_testing), such that users are assured that our code runs and passes tests.
Specifically, we set things up such that every push to Github results in a new build.
Dockerhub makes this easy.

All of these steps are shown in the example [cowsay-test repository](https://github.com/matsen/cowsay-test), which also has a suggested README structure.

1. Write a Dockerfile for your project. Test it either locally or on `exmar` (see below)
1. Add a YAML file that will trigger [Docker automated testing](https://docs.docker.com/docker-cloud/builds/automated-testing/). You should be able to copy this directly from the cowsay-test repository without modification.
1. Make an account on [Docker Hub](https://hub.docker.com/) if you don't have one already
1. Add a [Docker automated build](https://docs.docker.com/docker-hub/builds/)
1. Add a Docker build badge to your README (see cowsay-test; you'll need to change some things for that)


## Tips for making your Dockerfile

* Start with the best base image you can. If your code involves partis, use [Duncan's partis image](https://hub.docker.com/r/psathyrella/partis/). For R, see [rocker](https://hub.docker.com/u/rocker/). For conda, see [miniconda](https://hub.docker.com/r/continuumio/miniconda/).
* If you are installing dependencies via `pip`, `R`, or `conda`, go crazy with those.
* If you have binary dependencies (e.g. GSL) see the section below on apt.
* Erick's suggestion is to perform cycles of build, then interactive installation for the next step (cloning your repo inside the container), add to Dockerfile, repeat.
* Keep it clean-- don't add extra things you don't need, because others will be looking at your Dockerfile and using it as a guide for installing your software locally.
* Docker is very clever at caching partial execution, but this can be frustrating if something has been updated. To start from scratch, use the `--no-cache` flag to `docker build`.

### A tiny bit about apt

This section is only relevant for base images based eventually on Debian or Ubuntu (for the following instructions to work).
Definitely prefer those.

[apt](https://en.wikipedia.org/wiki/APT_(Debian)) is a wonderful package manager that was developed by Debian and adopted by Ubuntu (which is a Debian derivative).
[Here](http://www.tutonics.com/2012/10/a-faq-style-introduction-to-apt-get-and.html) is a FAQ with common commands.
For Docker, just use the following recipe:

```
RUN apt-get update && apt-get install -y --no-install-recommends \
    libgsl0-dev \
    libpng-dev
```

Replace `libgsl0-dev` and `libpng-dev` with what your image needs.

To find what you need, do the following.

1. Learn what version of Debian or Ubuntu you are using in your base image.
For example, if the base image is `debian:latest` you can go to [the corresponding Docker Hub page](https://hub.docker.com/r/_/debian/) to learn that this is Debian `stretch`.
1. Run your install until it says that it's missing some package or header file.
1. Look for `debian package <put in your package name here that you found from an error message>` on Google, which will take you to a page like [this](https://packages.debian.org/search?keywords=libpng). You can click on `stretch` to get more details on what's up with that package in the `stretch` version of Debian.
1. If you are working from within a container, you can run `apt-get install` directly from within the container and try your install again.
1. If it works, add that package name to your `apt-get install` list above.

Tip: packages that end with `-dev` are generally the ones you want, because they install libraries with the corresponding header files that you can use for compilation.


##
Docker has a beautiful [layered file system](https://docs.docker.com/terms/layer/), in which you only interact with the files on "top".
